{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch DataLoader\n",
    "\n",
    "It's not efficient to calculate the loss on all of the dataset, that's why we use batches of data and for each epoch, we loop over the batches and feed them one by one.\n",
    "\n",
    "In the Neural Network Termonology:\n",
    "* One `epoch`: One forward pass and one backward pass of all the training examples.\n",
    "* `Batch Size`: The number of training examples in one forward/backward pass. The Higher the batch size, the more memory space you'll need.\n",
    "* number of `iterations`: Number of passes, each pass using `batch size` number of examples. To be clear, one pass = one forward pass + one backward pass (we do not count the forward pass and backward pass as two different passes).\n",
    "\n",
    "Example: If you have 100 training examples, and the batch size is 500, you'll need 2 iterations to complete one epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how the DataLoader Works:\n",
    "\n",
    "<img src=\"DataLoader.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's how to work with data loaders in PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports.\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiabetesDataset(Dataset):\n",
    "    '''\n",
    "    The Diabetes Dataset class, based on Torch's Dataset Class.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        # download, read data etc..\n",
    "        # basically assigning a lot of selfs.\n",
    "        return\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # get data sample by index.\n",
    "        return\n",
    "    \n",
    "    def __len__(self):\n",
    "        # get the length of the available dataset.\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DiabetesDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A real example:\n",
    "<img src=\"DataLoaderExample.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There following dataset loaders are available:\n",
    "\n",
    "* MNIST and FashionMNIST\n",
    "* COCO (Captioning and Detection)\n",
    "* LSUN Classification\n",
    "* ImageFolder\n",
    "* ImageNet-l2\n",
    "* CIFAR10 - CIFAR100\n",
    "* STL10\n",
    "* SVHN\n",
    "* PhotoTour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the datasets above reside in `torchvision.datasets`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice\n",
    "Build a DataLoader for the Kaggle Titanic Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
