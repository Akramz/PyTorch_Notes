{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "<img src=\"CNNArchitecture.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole idea of convolutions is to focus on local dependencies and relations (like edges), and to compress information then look again, this will give an importance to the spacial structure images has.\n",
    "\n",
    "<img src=\"CNNLocality.png\" />\n",
    "\n",
    "Filters scan all of the image to produce a final activation of the image, we typically have more than one filter to capture the different dependencies between pixels, the weights are stored inside the filters, and filters product activations.\n",
    "\n",
    "The stride indicates how many steps the filter is going to move. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kernel of weights doesn't perform matrix multiplication, the activation is computed through the dot product of the turned vectors of the patch and the kernel weight values, an Example:\n",
    "\n",
    "<img src=\"CNNActivation.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Padding is Adding zeros on some boundaries to make the activation shape like the Input shape (in the case of stride is equal to one), padding examples:\n",
    "<img src=\"PaddingTypes.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filters always extend the full depth of the input volume (3 in an rgb image for example).\n",
    "\n",
    "The Number of filters will decide the depth of the generated maps (activations) and will serve as an input for the next convolution layer.\n",
    "\n",
    "<img src=\"ActivationDepth.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also use max-pooling to reduce the dimensionality of the input map, and also improves generalization (other methods are available like average pooling, but max-pooling remains the most used one):\n",
    "\n",
    "<img src=\"MaxPooling.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implement a Convolutional Neural Network for MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports.\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we download the MNIST Dataset.\n",
    "mnist_train = torchvision.datasets.MNIST(root='./data', \n",
    "                                         train=True, \n",
    "                                         download=True, \n",
    "                                         transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((.1307,), (.3081,))]))\n",
    "mnist_test  = torchvision.datasets.MNIST(root='./data', \n",
    "                                         train=False, \n",
    "                                         transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((.1307,), (.3081,))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then we load it.\n",
    "train_loader = DataLoader(dataset=mnist_train, batch_size=128, shuffle=True)\n",
    "test_loader  = DataLoader(dataset=mnist_test, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTClassifier(torch.nn.Module):\n",
    "    '''\n",
    "    We're going to use CNN + Dense layers to classify MNIST hadwritten digits.\n",
    "    Input: shape=(28,28) images of 1 channel.\n",
    "    Output: A probability distribution over the 10 labels (0,1,2,3,4,5,6,7,8,9).\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MNISTClassifier, self).__init__()\n",
    "        self.c1 = torch.nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5)\n",
    "        self.c2 = torch.nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5)\n",
    "        \n",
    "        self.d1 = torch.nn.Linear(in_features=320, out_features=10)  # figured this out from the error, find out a better way to inspect in_features.\n",
    "        \n",
    "        self.max_pooling = torch.nn.MaxPool2d(kernel_size=2) \n",
    "        self.relu        = torch.nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.max_pooling(self.c1(x)))\n",
    "        x = self.relu(self.max_pooling(self.c2(x)))\n",
    "        \n",
    "        # flatten the tensor.\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = self.d1(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to know the size of a tensor or anything, just inspect it outside the class and fill the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(model)\n",
    "model = MNISTClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNISTClassifier(\n",
       "  (c1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (c2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (d1): Linear(in_features=320, out_features=10, bias=True)\n",
       "  (max_pooling): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's take a look at the model's components.\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss & Optimizer Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    # set the model in training mode.\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # let's loop over the train_loader batches.\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, \n",
    "                                                                               batch_idx * len(data), \n",
    "                                                                               len(train_loader.dataset), \n",
    "                                                                               100. * batch_idx / len(train_loader), \n",
    "                                                                               loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 0.072837\n",
      "Train Epoch: 0 [1280/60000 (2%)]\tLoss: 0.099162\n",
      "Train Epoch: 0 [2560/60000 (4%)]\tLoss: 0.122402\n",
      "Train Epoch: 0 [3840/60000 (6%)]\tLoss: 0.188816\n",
      "Train Epoch: 0 [5120/60000 (9%)]\tLoss: 0.099456\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 0.161897\n",
      "Train Epoch: 0 [7680/60000 (13%)]\tLoss: 0.256982\n",
      "Train Epoch: 0 [8960/60000 (15%)]\tLoss: 0.123441\n",
      "Train Epoch: 0 [10240/60000 (17%)]\tLoss: 0.165172\n",
      "Train Epoch: 0 [11520/60000 (19%)]\tLoss: 0.166036\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.200613\n",
      "Train Epoch: 0 [14080/60000 (23%)]\tLoss: 0.167523\n",
      "Train Epoch: 0 [15360/60000 (26%)]\tLoss: 0.160424\n",
      "Train Epoch: 0 [16640/60000 (28%)]\tLoss: 0.162270\n",
      "Train Epoch: 0 [17920/60000 (30%)]\tLoss: 0.092106\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.157339\n",
      "Train Epoch: 0 [20480/60000 (34%)]\tLoss: 0.133018\n",
      "Train Epoch: 0 [21760/60000 (36%)]\tLoss: 0.143869\n",
      "Train Epoch: 0 [23040/60000 (38%)]\tLoss: 0.090167\n",
      "Train Epoch: 0 [24320/60000 (41%)]\tLoss: 0.140857\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.098282\n",
      "Train Epoch: 0 [26880/60000 (45%)]\tLoss: 0.226208\n",
      "Train Epoch: 0 [28160/60000 (47%)]\tLoss: 0.214356\n",
      "Train Epoch: 0 [29440/60000 (49%)]\tLoss: 0.100612\n",
      "Train Epoch: 0 [30720/60000 (51%)]\tLoss: 0.131197\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.048219\n",
      "Train Epoch: 0 [33280/60000 (55%)]\tLoss: 0.076848\n",
      "Train Epoch: 0 [34560/60000 (58%)]\tLoss: 0.183385\n",
      "Train Epoch: 0 [35840/60000 (60%)]\tLoss: 0.119654\n",
      "Train Epoch: 0 [37120/60000 (62%)]\tLoss: 0.078818\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.131575\n",
      "Train Epoch: 0 [39680/60000 (66%)]\tLoss: 0.091425\n",
      "Train Epoch: 0 [40960/60000 (68%)]\tLoss: 0.228551\n",
      "Train Epoch: 0 [42240/60000 (70%)]\tLoss: 0.057408\n",
      "Train Epoch: 0 [43520/60000 (72%)]\tLoss: 0.201507\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.080878\n",
      "Train Epoch: 0 [46080/60000 (77%)]\tLoss: 0.138025\n",
      "Train Epoch: 0 [47360/60000 (79%)]\tLoss: 0.205879\n",
      "Train Epoch: 0 [48640/60000 (81%)]\tLoss: 0.183625\n",
      "Train Epoch: 0 [49920/60000 (83%)]\tLoss: 0.067696\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.207645\n",
      "Train Epoch: 0 [52480/60000 (87%)]\tLoss: 0.130697\n",
      "Train Epoch: 0 [53760/60000 (90%)]\tLoss: 0.154160\n",
      "Train Epoch: 0 [55040/60000 (92%)]\tLoss: 0.049589\n",
      "Train Epoch: 0 [56320/60000 (94%)]\tLoss: 0.099539\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.074840\n",
      "Train Epoch: 0 [58880/60000 (98%)]\tLoss: 0.120291\n"
     ]
    }
   ],
   "source": [
    "train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate():\n",
    "    \n",
    "    # sets the model in evaluation mode.\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for data, target in test_loader:\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        \n",
    "        # sum up batch loss.\n",
    "        test_loss += criterion(output, target).data[0]\n",
    "        # get the index of the max log probability.\n",
    "        pred = torch.max(output.data, 1)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nValidation set Loss: {:.4f}, accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, \n",
    "                                                                              correct, \n",
    "                                                                              len(test_loader.dataset), \n",
    "                                                                              100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set Loss: 0.0007, accuracy: 9714/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice: Implement More CNN Layers\n",
    "<img src=\"MoreCNNLayers.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
